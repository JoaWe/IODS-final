#Datawrangling and Explanation of the Dataset

The dataset that is used here is a modified combination of the [Human Development Index](http://hdr.undp.org/en/content/human-development-index-hdi) and the [Gender Inequality Index](http://hdr.undp.org/en/content/gender-inequality-index-gii) published by the United Nations Development Programme for the year 2016.

The datasets contained originally 8 variables for the Human Development Index and 10 for the Gender Inequality Index. Either set presented a total of 195 observations for most of the world's countries and 7 regions.

However, the dataset used here has been - as mentioned above - modified by means of datawrangling with RStudio. The dataset now contains 155 observations and 8 variables:

1. **Life_Exp**, which refers to the average number of years of life-espectancy of a country's population 

2. **Exp_Edu**, which refers to the expected number of school years of a country's population

3. **GNI**, which refers to the respective country's gross domestic product

4. **MMR**, which refers to a country's maternal mortality ratio in terms of deaths per 100,000 live births

5. **ABR**, which refers to a country's respective Ratio of births given by adolescents, in terms of births per 1,000 women between the ages of 15 to 19 

6. **PRP**, which refers to the share of parliamentary seats held by women in percent

7. **sec_Edu**, which refers to the population aged 25 or above with at least some secondary education in a country presented in percent

8. **LF**, which refers to the Labour force participation rate of a countries population (15 years of age or older)

The link to my coding of the datawrangling can be found from [here](https://github.com/JoaWe/IODS-final/blob/master/create_fa_human.R).

The modifications are as follows:

1. The variable-names have been shortened.
2. The two separate datasets have been joined by the variable "Country", which existed in both datasets, and has later been used to replace the rownames.
3. The 7 regions have been removed from the dataset, resulting in a dataset containing only country-observations.
4. Missing values have been removed from the dataset, so that the dataset contains only complete sets.
5. The rows of the dataset have been sorted by the observations of the variable "GNI"
      
```{r accessing libraries & loading the dataset fa_human}

# accessing libraries
library(dplyr)

# loading human:
fa_human <- read.table("C:\\Users\\Ani\\Documents\\GitHub\\IODS-final\\fa_human.csv", sep = ",", header = TRUE, row.names = 1)

```

In order to give a general overview over the data, you can see the summary and a simple plot here:
```{r summary}

# Accessing libraries for plots:
library(GGally)
library(corrplot)

# Summarizing the dataset for a brief overview:
summary(fa_human)

# using corrplot to visualize the dataset in a simple manner:
cor(fa_human)%>%corrplot(method = "color")

# using ggpairs for more extensive visualization of the dataset:
ggpairs(fa_human)

```

*The first plot is to be read by the shades of red (= negative correlation) and blue (positive correlation). The darker the respective shade the stronger the supposed correlation.The second plot shows the correlation-coefficiants between the variables on the right upper side. The left lower side provides a rough overview of the dispersion of the respective observations.*

As can be seen from the plots above the maternal mortality rate appears (MMR) to be having a particularly obvious negative correlation with the average life-expectancy (Life_Exp), the expected years of education (Exp_Edu), and a population with at least some degree of secondary education (sec_Edu). 

A strong positive correlation appears to be existing between the maternal mortality rate and the adolescent birthrate (ABR). Similarly positive appears to be the impact between the variables of expected education and the life-expectancy. 

And finally, slightly weaker, yet still obvious appears to be the positive correlation between at least some degree of secondary education to the variables life-expectancy and expected years of education.

Accordingly, it appears to be sensible to take a few of these variables and their relationships under closer scrutiny.


#Hypotheses

1. The variables Life_Exp and MMR are strongly negatively correlated: **It can therefore be assumed that countries with a lower maternal mortality rate will display a higher life-expectancy in years.** Simple linear & logistic regression models ought to show the truth or falsehood of this hypothesis. It may also be interesting to see, which might fit more.

2. The variables Exp_Edu and sec_Eduare strongly negatively correlated with the variable MMR: **It can be assumed that an increase of education can have a decreasing effect on the maternal mortality rate**. Similarly as before, linear and logistic regression models ought to be sufficient to prove or disprove the hypothesis. Yet, the results ought to differ at least a little from the former hypothesis, as in this case the models will be based on multiple regression.

3. The GNI


# 1. Life-Expectancy & Maternel Mortality Rate


### Basic Hypothesis:
**Countries with a lower mortality rate are expected to display a higher average life-expectancy.**


### Method: Linear Regression:
Linear regression analysis is used in order to relate to variables with one another. The independent variable thereby is believed to be the cause for the dependent variable, leading to the understanding that *if **x**, then **y** *.

A line is thereby drawn that - hopefully - fits as many observations as possible onto itself. Yet, in reality, the coinciding of all observations with *one particular line* is rather unlikely. Thus, the line is sought that is closest to at least most of the observations. Another problem might be, however, that more than one line can be correct.

The basic formular for this line is considered to be **y = a + bx**. The parameter **a** defines the line's y-intercept, while **b** determines the line's slope.

The manner in which the above hypothesis is presented the maternal mortality rate is used to explain the life-expectancy. Therefore,the definition of the variables is the following:

- **independent variable = MMR**
- **dependent variable = Life_Exp**


#### Applying Linear Regression Analysis:

```{r LinRA Life-Exp & MMR, fig.height=4, fig.width=6}

# Accessing library:
library(ggplot2)

# drawing the plot:
qplot(MMR, Life_Exp, data = fa_human) + geom_smooth(method = "lm")

# fitting the linear model:
Life_MDeath <- lm(MMR ~ Life_Exp, data = fa_human)

# Printing the model's summary
summary(Life_MDeath)

```

With regard to the graph above, the line is "falling" the further the observations get away from the y-axis (meaning an increase in the independent variable). Thus, the above hypothesis can be considered as "not being wrong": The higher the maternal mortality rate is, the lower is the life-expectancy. 

I chose the term "not wrong" intentionally for expressing the hypothesis' validity, however, because when focusing on the graph, it does show that quite a number of observations is not even remotely found near the line. Which is why the summary helps to further analyze the results.

Of particular interest is, for instance, the multiple *r-sqared*, which if it were in perfect synchronization, were to reach the value of 1. In the case of this analysis, however, it reaches 0,7347. Thus, it implies that less than 75% (73,47%) of the variablity is explained by this linear regression model.

It remains to be seen, if the logistic regresssion might not lead to a more suitable result.


### Method: Logistic Regression:
The basis of logistic regression is the same as linear regression: An independent variable is drawn upon, in order to explain a dependent variable.

The difference, however, is that in this case it is not a linear but an exponential function that is sought in order to provide an explanation for the dependence.

#### Applying Logistic Regression:

The variables MMR and Life_Exp will be used in the same manner as above in the linear regression model:

- **independent variable = MMR**
- **dependent variable = Life_Exp**

```{r LogRA Life_exp & MMR}

# Accessing libraries:
library(tidyr)

# fitting the logistic model:
Life_MDeath_log <- glm(MMR ~ Life_Exp, data = fa_human)

# Printing the model's summary
summary(Life_MDeath_log)

```

As can be seen in the section on coefficients the logistic regression analysis contains only the one constant "Life_Exp". The coefficient associated with the variable is -21,788 and it represents the log-odds by which the value of the observation were to increase, if the variable were to increase by one unit. 

The negative coefficient confirms the negative correlation between the variables. Meaning that, for example, it is likely that the life-expectancy is likely to increase if the maternal mortality rate were to got down. The value itself implies a high significance.


#2. Maternal Mortality and Education:

### Basic Hypothesis:
**An increase of education can have a decreasing effect on the maternal mortality rate.**

### Applying multiple logistic regression:

- **dependent variable = MMR**
- **1. independent variable = sec_Edu**
- **2. independent variable = Exp_Edu**

```{r multipleLogRA Education & MMR}

# Accessing libraries:
library(tidyr)
library(ggplot2)

# fitting the logistic model:
Edu_MDeath_expo <- glm(MMR ~ sec_Edu + Exp_Edu, data = fa_human)

# Printing the model's summary
summary(Edu_MDeath_expo)

```

In this multiple logicstic regression analysis I related the variables sec_Edu and Exp_Edu to the variable MMR. 
Differently from the analysis before we now have two  constants. Both again have negative coefficients, which means that an in- or de-crease in either would affect the maternal mortality rate in the respective reverse. It appears hereby that particularly the access to a secondary education impacts on the MMR-variable.

# Maternal-Mortality-Rate & Adolescent Birthrate:

### Basic Hypothesis

**It can be assumed that an increase in births given by adolescents might increase the number of mothers dying during birth, and vice versa.** 

### Linear Discriminant Analysis:


Linear Discriminant Analysis (LDA) is a classificatiton method, used to find  variables that separate the dataset, predict "classes" of new data, and reduce the dimensions of the dataset. 

1. Step scaling the dataset:

```{r scaling dataset}

# center and standardize variables
fa_human_scaled <- scale(fa_human)

# summaries of the scaled variables
summary(fa_human_scaled)

# class of the boston_scaled object
class(fa_human_scaled)

# change the object to data frame
fa_human_scaled <- as.data.frame(fa_human_scaled)

```


2. Creating a categorical variable:

```{r creating factor-variable gni}

# summary of the scaled GNI-variable
summary(fa_human_scaled$GNI)

# create a quantile vector of GNI and print it
bins <- quantile(fa_human_scaled$GNI)
bins

# create a categorical variable "gni"
gni <- cut(fa_human_scaled$GNI, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))

# look at the table of the new factor gni
table(gni)

# remove original GNI from the dataset
fa_human_scaled <- dplyr::select(fa_human_scaled, -GNI)

# add the new categorical value to scaled data
fa_human_scaled <- data.frame(fa_human_scaled, gni)

```

3. Creating train- and test-sets:

```{r train & testsets}
# number of rows in the scaled dataset:
n <- nrow(fa_human_scaled)

# Choose 75% of the rows
ind <- sample(n, size = n*0,75)

# creating the trainset:
train <- fa_human_scaled[ind,]

# creating the testset:
test <- fa_human_scaled[-ind,]

# saving the correct cclasses from the test data:
correct_classes <- test$gni

#removing the gni-variable from the testset:
test <- dplyr::select(test, -gni)

```

4. LDA and the trainset:

```{r train gni-LDA}


# Accessing library:
library(MASS)

# linear discriminant analysis:
lda.fit <- lda(gni~., data = train)

#printing lda.fit-object:
lda.fit

# function for the lda-biplot arrows:
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0,
         x1 = myscale * heads[,choices[1]],
         y1 = myscale * heads[,choices[2]],
         col = color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), cex = tex, col = color, pos = 3)
}

```